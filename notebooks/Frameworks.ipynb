{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Machine Learning Applications for Physicists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Material for a* [*University of Illinois*](http://illinois.edu) *course offered by the* [*Physics Department*](https://physics.illinois.edu). *This content is maintained on* [*GitHub*](https://github.com/illinois-mla) *and is distributed under a* [*BSD3 license*](https://opensource.org/licenses/BSD-3-Clause).\n",
    "\n",
    "[Table of contents](Contents.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mls import plot_rosenbrock, plot_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we introduce on some useful frameworks for practical calculations, rather than describe any new techniques.  We consider two types of frameworks:\n",
    " - Frameworks to build and efficiently run a computational graph.\n",
    " - Frameworks for [probabilistic programming](https://en.wikipedia.org/wiki/Probabilistic_programming_language).\n",
    " \n",
    "Note that a probabilistic programming framework often builds on a lower-level computational graph framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Graphs: Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning architectures around computations graphs very powerful\n",
    "* define a computation graph\n",
    "* provide data and a training strategy (e.g., batching)\n",
    "* toolkit does the rest\n",
    "\n",
    "TensorFlow is a graph based processing framework that is really well suited for building Machine Learning models. TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n",
    "\n",
    "https://www.tensorflow.org/programmers_guide/low_level_intro#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: calculation with constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple calculation in python involving constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1.0\n",
    "b = 2.0\n",
    "c = a + b\n",
    "print(' a = {}\\n b = {}\\n c = {}'.format(a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow equivalent is more involved since it requires two stages. First, we build a graph, which captures the structure of the calculation but contains no values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    a = tf.constant(1.0, name='a')\n",
    "    b = tf.constant(2.0, name='b')\n",
    "    c = tf.add(a, b, name='c') # a + b also valid but is un-named.\n",
    "print(' a = {}\\n b = {}\\n c = {}'.format(a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tensorboard` program allows graphs (and summary results) to be visualized in the browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter('tfs/intro1', graph=g1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "% tensorboard --logdir tfs/intro1 --host localhost --port=8080\n",
    "TensorBoard 1.5.1 at http://localhost:6006 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sum graph](img/Frameworks/sum_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second stage is to run the graph in a session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g1) as s1:\n",
    "    c_out = s1.run(c)\n",
    "print(' c = {}'.format(c_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: calculation with variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    x0, x1 = x\n",
    "    a, b = 1., 100.\n",
    "    return (a - x0) ** 2 + b * (x1 - x0 ** 2) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rosenbrock([1., 1.]))\n",
    "print(rosenbrock([0.5, -0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(2,), name='x')\n",
    "    x0 = tf.slice(x, [0], [1], name='x0')\n",
    "    x1 = tf.slice(x, [1], [1], name='x1')\n",
    "    a = tf.constant(1., name='a')\n",
    "    b = tf.constant(100., name='b')\n",
    "    with tf.name_scope('rosenbrock'):\n",
    "        rosenbrock = (a - x0) ** 2 + b * (x1 - x0 ** 2) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter('tfs/intro2', graph=g2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new tensorboard graph is:\n",
    "\n",
    "![rosenbrock graph](img/Frameworks/rosenbrock_graph.png)\n",
    "\n",
    "Double clicking on the \"rosenbrock\" node reveals its internal structure, composed of primitive building blocks:\n",
    "\n",
    "![rosenbrock graph](img/Frameworks/rosenbrock_graph2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g2) as s2:\n",
    "    print(s2.run(rosenbrock, feed_dict={x: [1., 1.]}))\n",
    "    print(s2.run(rosenbrock, feed_dict={x: [0.5, -0.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the line:\n",
    "```\n",
    "    rosenbrock_grad = tf.gradients(rosenbrock, [x])\n",
    "```\n",
    "to the example above to extend the graph to calculate the partial derivatives of the Rosenbrock function with respect to the components of `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = tf.Graph()\n",
    "with g3.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(2,), name='x')\n",
    "    x0 = tf.slice(x, [0], [1], name='x0')\n",
    "    x1 = tf.slice(x, [1], [1], name='x1')\n",
    "    a = tf.constant(1., name='a')\n",
    "    b = tf.constant(100., name='b')\n",
    "    with tf.name_scope('rosenbrock'):\n",
    "        rosenbrock = (a - x0) ** 2 + b * (x1 - x0 ** 2) ** 2\n",
    "    rosenbrock_grad = tf.gradients(rosenbrock, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter('tfs/intro3', graph=g3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g3) as s3:\n",
    "    print(s3.run(rosenbrock_grad, feed_dict={x: [1., 1.]}))\n",
    "    print(s3.run(rosenbrock_grad, feed_dict={x: [0.5, -0.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the lines:\n",
    "```\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.05, name='optimizer')\n",
    "    step = optimizer.minimize(rosenbrock, name='step')\n",
    "```\n",
    "to extend the graph to perform optimization, i.e., to iteratively update `x` to move towards a (local) minimum. We also need to change `x` from a `placeholder` to a `Variable` since it is now being updated internally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4 = tf.Graph()\n",
    "with g4.as_default():\n",
    "    x = tf.Variable([-1., 0.], name='x')\n",
    "    x0 = tf.slice(x, [0], [1], name='x0')\n",
    "    x1 = tf.slice(x, [1], [1], name='x1')\n",
    "    a = tf.constant(1., name='a')\n",
    "    b = tf.constant(100., name='b')\n",
    "    with tf.name_scope('rosenbrock'):\n",
    "        rosenbrock = (a - x0) ** 2 + b * (x1 - x0 ** 2) ** 2\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.05, name='optimizer')\n",
    "    step = optimizer.minimize(rosenbrock, name='step')\n",
    "    initialize = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph knows what variables it can be optimized (trained) over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4.get_collection('trainable_variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the optimizer in a session and save its path. You can also [save summary data](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard#serializing_the_data) to the log file for later inspection in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g4) as s4:\n",
    "    s4.run(initialize)\n",
    "    path = [s4.run(x)]\n",
    "    for i in range(2000):\n",
    "        s4.run(step)\n",
    "        path.append(s4.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the [Adam optimizer](https://arxiv.org/abs/1412.6980) is relatively new (2014) and not yet implemented (as of 2018) in `scipy.optimize`, but is popular for deep-learning optimization. In this example, it quickly finds the curved valley, but requires many steps to zero in on its shallow minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rosenbrock(path=path);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
